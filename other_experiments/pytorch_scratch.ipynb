{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7cf1a457-8d4b-4089-b6f4-d0670fa67c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1100, 15)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "original_data = np.genfromtxt('../../../working_data/normalised_delta_updrs_sigfall.csv', delimiter=',', skip_header=True)\n",
    "_, n_columns = original_data.shape\n",
    "\n",
    "data = original_data[:,0:(n_columns - 1)]\n",
    "labels = original_data[:,(n_columns - 1)]\n",
    "\n",
    "full_train = original_data[0:1100]\n",
    "full_test  = original_data[1101:1452]\n",
    "\n",
    "xx_train = data[0:1000]\n",
    "xx_test = data[1001:1400]\n",
    "yy_test  = labels[1001:1400]\n",
    "yy_train = labels[0:1000]\n",
    "\n",
    "full_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f69bc85d-a01e-4cba-97cb-723c9a430477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders for our datasets; shuffle for training, not for validation\n",
    "training_loader = torch.utils.data.DataLoader(full_train, batch_size=4, shuffle=True, num_workers=2)\n",
    "validation_loader = torch.utils.data.DataLoader(full_test, batch_size=4, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9460d130-71ea-43ef-b809-75c699727dbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TinyModel(\n",
       "  (input): Linear(in_features=13, out_features=25, bias=True)\n",
       "  (activation): Sigmoid()\n",
       "  (hidden1): Linear(in_features=25, out_features=10, bias=True)\n",
       "  (output): Linear(in_features=10, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TinyModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(TinyModel, self).__init__()\n",
    "\n",
    "        self.input = torch.nn.Linear(13, 25) # 14-25-10-1\n",
    "        self.activation = torch.nn.Sigmoid()\n",
    "        self.hidden1 = torch.nn.Linear(25, 10)\n",
    "        self.output = torch.nn.Linear(10, 1)\n",
    "        \n",
    "        torch.nn.init.xavier_uniform_(self.input.weight)\n",
    "        torch.nn.init.zeros_(self.input.bias)\n",
    "        torch.nn.init.xavier_uniform_(self.hidden1.weight)\n",
    "        torch.nn.init.zeros_(self.hidden1.bias)\n",
    "        torch.nn.init.xavier_uniform_(self.output.weight)\n",
    "        torch.nn.init.zeros_(self.output.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.hidden1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.output(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "    \n",
    "model = TinyModel()\n",
    "model.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "80317884-42b5-4348-a8e8-125488e82d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers specified in the torch.optim package\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7dc47647-154a-493b-9ce2-25370f2c742f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "loss_fn = torch.nn.BCELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e269e989-2d22-4ba9-ac0f-74ef52bcf724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Test the nn\n",
    "\n",
    "x = full_train[3]\n",
    "x_tensor = torch.from_numpy(x[0:13]).float()\n",
    "y = model(x_tensor)\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ccdafabf-8a97-421d-9188-d27078b160a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([1.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([1.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([1.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([1.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([1.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([1.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([1.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([1.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([1.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([1.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([1.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([1.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([1.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([1.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([1.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([1.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([1.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([1.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([1.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.5310], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.])\n"
     ]
    }
   ],
   "source": [
    "for i, x in enumerate(training_loader):\n",
    "    label = x[0,14].float().reshape(1)\n",
    "    inputs = x[0,0:13].float()\n",
    "\n",
    "    # Zero your gradients for every batch!\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Make predictions for this batch\n",
    "    y = model(inputs)\n",
    "    # Compute the loss and its gradients\n",
    "    print(y)\n",
    "    print(label)\n",
    "    loss = loss_fn(y, label)\n",
    "    loss.backward()\n",
    "\n",
    "    # Adjust learning weights\n",
    "    optimizer.step()\n",
    "   \n",
    "    # so it actually trains now \n",
    "    # so why does it keep plopping out the same result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c553f1-5228-4b29-a9f6-e0e43aa6106f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
