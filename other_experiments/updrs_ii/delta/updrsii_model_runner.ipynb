{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "33c336da-60de-4d3d-bc0c-2a5f46676197",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import optunity\n",
    "import optunity.metrics\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# from sklearn.preprocessing import normalize\n",
    "\n",
    "# short form for now\n",
    "original_data = np.genfromtxt('../../working_data/updrsii_short_form.csv', delimiter=',', skip_header=True)\n",
    "n_rows, n_columns = original_data.shape\n",
    "\n",
    "data = original_data[:,0:(n_columns - 1)]\n",
    "labels = original_data[:,(n_columns - 1)]\n",
    "\n",
    "# Common cross validator for all models\n",
    "cv_decorator = optunity.cross_validated(x=data, y=labels, num_folds=10)\n",
    "\n",
    "results = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c12ed93-8cdb-43f5-9332-99d0b2709ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal parameters{'sigfall_prior': 0.024700000000000024}\n",
      "AUROC of tuned model: 0.633\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "def gnb_tuned_auroc(x_train, y_train, x_test, y_test, sigfall_prior):\n",
    "    no_fall_prior = 1.0 - sigfall_prior\n",
    "    model = GaussianNB(priors=[no_fall_prior,sigfall_prior]).fit(x_train, y_train)\n",
    "    decision_values = model.predict(x_test)\n",
    "    auc = optunity.metrics.roc_auc(y_test, decision_values)\n",
    "    return auc\n",
    "    \n",
    "    \n",
    "gnb_tuned_auroc = cv_decorator(gnb_tuned_auroc)\n",
    "gnb_optimal_pars, gnb_info, _ = optunity.maximize(gnb_tuned_auroc, solver_name='grid search', num_evals=100, sigfall_prior=[0.01,0.99])\n",
    "\n",
    "print(\"Optimal parameters\" + str(gnb_optimal_pars))\n",
    "print(\"AUROC of tuned model: %1.3f\" % gnb_info.optimum)\n",
    "\n",
    "results.append({'model': 'Gaussian Naive Bayes',\n",
    "               'Optimal parameters': gnb_optimal_pars,\n",
    "               'ROC_AUC': gnb_info.optimum\n",
    "               })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a2efc1da-dc09-4d03-879b-9be1289f6e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00174379, 0.00102305, 0.00102558, 0.00101542, 0.00106082,\n",
       "        0.00085592]),\n",
       " 'std_fit_time': array([4.82738008e-04, 2.21816425e-04, 1.71388144e-04, 2.38362258e-04,\n",
       "        1.20339529e-04, 2.08574700e-05]),\n",
       " 'mean_score_time': array([0.00120292, 0.0006485 , 0.00061941, 0.0005538 , 0.00066643,\n",
       "        0.00045686]),\n",
       " 'std_score_time': array([5.42386214e-04, 1.35459022e-04, 1.94462822e-04, 8.09670899e-05,\n",
       "        7.78874344e-05, 6.04687802e-05]),\n",
       " 'param_priors': masked_array(data=[list([0.01, 0.99]), list([0.2, 0.8]), list([0.3, 0.7]),\n",
       "                    list([0.7, 0.3]), list([0.8, 0.2]), list([0.01, 0.99])],\n",
       "              mask=[False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'priors': [0.01, 0.99]},\n",
       "  {'priors': [0.2, 0.8]},\n",
       "  {'priors': [0.3, 0.7]},\n",
       "  {'priors': [0.7, 0.3]},\n",
       "  {'priors': [0.8, 0.2]},\n",
       "  {'priors': [0.01, 0.99]}],\n",
       " 'split0_test_score': array([0.1375, 0.175 , 0.5125, 0.8125, 0.8125, 0.1375]),\n",
       " 'split1_test_score': array([0.125 , 0.225 , 0.3625, 0.8375, 0.8375, 0.125 ]),\n",
       " 'split2_test_score': array([0.125, 0.175, 0.375, 0.825, 0.825, 0.125]),\n",
       " 'split3_test_score': array([0.125 , 0.1625, 0.1875, 0.8875, 0.8875, 0.125 ]),\n",
       " 'split4_test_score': array([0.125 , 0.125 , 0.15  , 0.8875, 0.8875, 0.125 ]),\n",
       " 'mean_test_score': array([0.1275, 0.1725, 0.3175, 0.85  , 0.85  , 0.1275]),\n",
       " 'std_test_score': array([0.005     , 0.03201562, 0.13290034, 0.03162278, 0.03162278,\n",
       "        0.005     ]),\n",
       " 'rank_test_score': array([5, 4, 3, 1, 1, 5], dtype=int32)}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3518f101-02b8-4829-8c25-189fe65c8c02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00289783, 0.00142674, 0.00104995, 0.00087023, 0.00102296,\n",
       "        0.00095797]),\n",
       " 'std_fit_time': array([7.76019896e-04, 3.82517996e-04, 1.33545685e-04, 5.17318873e-05,\n",
       "        1.86303555e-04, 1.56258889e-04]),\n",
       " 'mean_score_time': array([0.00284405, 0.00077724, 0.00056081, 0.00048723, 0.00053992,\n",
       "        0.00058551]),\n",
       " 'std_score_time': array([2.04552010e-03, 3.36450230e-04, 1.14658407e-04, 6.32239321e-05,\n",
       "        4.54142273e-05, 1.27651400e-04]),\n",
       " 'param_priors': masked_array(data=[list([0.01, 0.99]), list([0.2, 0.8]), list([0.3, 0.7]),\n",
       "                    list([0.7, 0.3]), list([0.8, 0.2]), list([0.01, 0.99])],\n",
       "              mask=[False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'priors': [0.01, 0.99]},\n",
       "  {'priors': [0.2, 0.8]},\n",
       "  {'priors': [0.3, 0.7]},\n",
       "  {'priors': [0.7, 0.3]},\n",
       "  {'priors': [0.8, 0.2]},\n",
       "  {'priors': [0.01, 0.99]}],\n",
       " 'split0_test_score': array([0.1375, 0.175 , 0.5125, 0.8125, 0.8125, 0.1375]),\n",
       " 'split1_test_score': array([0.125 , 0.225 , 0.3625, 0.8375, 0.8375, 0.125 ]),\n",
       " 'split2_test_score': array([0.125, 0.175, 0.375, 0.825, 0.825, 0.125]),\n",
       " 'split3_test_score': array([0.125 , 0.1625, 0.1875, 0.8875, 0.8875, 0.125 ]),\n",
       " 'split4_test_score': array([0.125 , 0.125 , 0.15  , 0.8875, 0.8875, 0.125 ]),\n",
       " 'mean_test_score': array([0.1275, 0.1725, 0.3175, 0.85  , 0.85  , 0.1275]),\n",
       " 'std_test_score': array([0.005     , 0.03201562, 0.13290034, 0.03162278, 0.03162278,\n",
       "        0.005     ]),\n",
       " 'rank_test_score': array([5, 4, 3, 1, 1, 5], dtype=int32)}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GNB via in house hyperparameter optimzers\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "x_train = data[0:400,:]\n",
    "y_train = labels[0:400]\n",
    "\n",
    "parameters = {'priors':[[0.01,0.99], [0.2,0.8], [0.3,0.7], [0.7,0.3], [0.8,0.2], [0.01,0.99]]}\n",
    "gnb = GaussianNB()\n",
    "clf = GridSearchCV(gnb, parameters)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bc5410af-399b-4906-8a83-6153497e4a1c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rf_optimal_pars' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 29>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m forest_tuned_auroc \u001b[38;5;241m=\u001b[39m cv_decorator(forest_tuned_auroc)\n\u001b[1;32m     27\u001b[0m rf_optimal_pairs, rf_info, _ \u001b[38;5;241m=\u001b[39m optunity\u001b[38;5;241m.\u001b[39mmaximize_structured(forest_tuned_auroc, search_space\u001b[38;5;241m=\u001b[39mforest_space, num_evals\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimal parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[43mrf_optimal_pars\u001b[49m))\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAUROC of tuned RF: \u001b[39m\u001b[38;5;132;01m%1.3f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m rf_info\u001b[38;5;241m.\u001b[39moptimum)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rf_optimal_pars' is not defined"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest_space = { 'criterion': {\n",
    "        'gini': {'n_estimators': [50,200], 'cwn': [1,3]},\n",
    "        'entropy': {'n_estimators': [50,200], 'cwn': [1,3]},\n",
    "        'log_loss': {'n_estimators': [50,200], 'cwn': [1,3]}\n",
    "    }\n",
    "}\n",
    "\n",
    "def forest_tuned_auroc(x_train, y_train, x_test, y_test, criterion, n_estimators, cwn):\n",
    "    c = int(cwn)\n",
    "    nest = math.floor(n_estimators)\n",
    "    if c == 1 :\n",
    "        class_weight = 'balanced'\n",
    "    elif c == 2 :\n",
    "        class_weight = 'balanced_subsample'\n",
    "    else :\n",
    "        class_weight = None\n",
    "        \n",
    "    model = RandomForestClassifier(criterion=criterion, n_estimators=nest, class_weight = class_weight).fit(x_train, y_train)\n",
    "    decision_values = model.predict(x_test)\n",
    "    auc = optunity.metrics.roc_auc(y_test, decision_values)\n",
    "    return auc\n",
    "\n",
    "forest_tuned_auroc = cv_decorator(forest_tuned_auroc)\n",
    "rf_optimal_pairs, rf_info, _ = optunity.maximize_structured(forest_tuned_auroc, search_space=forest_space, num_evals=100)\n",
    "\n",
    "print(\"Optimal parameters\" + str(rf_optimal_pairs))\n",
    "print(\"AUROC of tuned RF: %1.3f\" % rf_info.optimum)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "334a266a-faed-4bc9-bab4-708e410eb628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal parameters{'n_estimators': 72.5, 'lrate': 1.045}\n",
      "AUROC of tuned model: 0.543\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "def ada_tuned_auroc(x_train, y_train, x_test, y_test, n_estimators, lrate):\n",
    "    nest = math.floor(n_estimators)\n",
    "    model = AdaBoostClassifier(n_estimators=nest, learning_rate=lrate).fit(x_train, y_train)\n",
    "    decision_values = model.predict(x_test)\n",
    "    auc = optunity.metrics.roc_auc(y_test, decision_values)\n",
    "    return auc\n",
    "\n",
    "ada_tuned_auroc = cv_decorator(ada_tuned_auroc)\n",
    "ada_optimal_pars, ada_info, _ = optunity.maximize(ada_tuned_auroc, solver_name='grid search', num_evals=100, n_estimators=[50,150], lrate=[1, 10])\n",
    "\n",
    "print(\"Optimal parameters\" + str(ada_optimal_pars))\n",
    "print(\"AUROC of tuned model: %1.3f\" % ada_info.optimum)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
