{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3228c38a-98d0-4042-9704-39f199e1b10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import optunity\n",
    "import optunity.metrics\n",
    "\n",
    "original_data = np.genfromtxt('../../../working_data/normalised_delta_updrs_sigfall.csv', delimiter=',', skip_header=True)\n",
    "_, n_columns = original_data.shape\n",
    "\n",
    "data = original_data[:,0:(n_columns - 1)]\n",
    "labels = original_data[:,(n_columns - 1)]\n",
    "\n",
    "# Common cross validator for all models\n",
    "cv_decorator = optunity.cross_validated(x=data, y=labels, num_folds=10)\n",
    "\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bdd6087f-d305-48be-af1a-1c38ba3ebbef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal parameters{'sigfall_prior': 0.7695}\n",
      "AUROC of tuned model: 0.683\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "def gnb_tuned_auroc(x_train, y_train, x_test, y_test, sigfall_prior):\n",
    "    no_fall_prior = 1.0 - sigfall_prior\n",
    "    model = GaussianNB(priors=[no_fall_prior,sigfall_prior]).fit(x_train, y_train)\n",
    "    decision_values = model.predict(x_test)\n",
    "    auc = optunity.metrics.roc_auc(y_test, decision_values)\n",
    "    return auc\n",
    "    \n",
    "    \n",
    "gnb_tuned_auroc = cv_decorator(gnb_tuned_auroc)\n",
    "gnb_optimal_pars, gnb_info, _ = optunity.maximize(gnb_tuned_auroc, solver_name='grid search', num_evals=100, sigfall_prior=[0.01,0.99])\n",
    "\n",
    "print(\"Optimal parameters\" + str(gnb_optimal_pars))\n",
    "print(\"AUROC of tuned model: %1.3f\" % gnb_info.optimum)\n",
    "\n",
    "results.append({'model': 'Gaussian Naive Bayes',\n",
    "               'Optimal parameters': gnb_optimal_pars,\n",
    "               'ROC_AUC': gnb_info.optimum\n",
    "               })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "daf7d685-9133-466d-a4f7-669459b7c180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal parameters{'kernel': 'rbf', 'C': 4.973967190410129, 'sigfall_class_weight': 6.765950520833336, 'coef0': None, 'degree': None, 'logGamma': -3.4251259403278747}\n",
      "AUROC of tuned SVM: 0.729\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machines\n",
    "import sklearn.svm\n",
    "\n",
    "# Finding the optimum SVM by abstracting over possible Kernel functions:\n",
    "space = {'kernel': {'linear': {'C': [0, 2], 'sigfall_class_weight':[0,25]},\n",
    "                    'rbf': {'logGamma': [-5, 0], 'C': [0, 10], 'sigfall_class_weight':[0,25]},\n",
    "                    'poly': {'degree': [2, 5], 'C': [0, 5], 'coef0': [0, 2], 'sigfall_class_weight':[0,25]}\n",
    "                    }\n",
    "         }\n",
    "\n",
    "# Need to use conditional func because sci-kit wont take None argument types\n",
    "def train_model(x_train, y_train, kernel, C, logGamma, degree, coef0, sigfall_class_weight):\n",
    "    if kernel == 'linear':\n",
    "        model = sklearn.svm.SVC(kernel=kernel, C=C, class_weight={1: sigfall_class_weight})\n",
    "    elif kernel == 'poly':\n",
    "        model = sklearn.svm.SVC(kernel=kernel, C=C, degree=degree, coef0=coef0, class_weight={1: sigfall_class_weight})\n",
    "    elif kernel == 'rbf':\n",
    "        model = sklearn.svm.SVC(kernel=kernel, C=C, gamma=10 ** logGamma, class_weight={1: sigfall_class_weight})\n",
    "    else:\n",
    "        raise ArgumentError(\"Unknown kernel function: %s\" % kernel)\n",
    "    model.fit(x_train, y_train)\n",
    "    return model\n",
    "\n",
    "def svm_tuned_auroc(x_train, y_train, x_test, y_test, kernel='linear', C=0, logGamma=0, degree=0, coef0=0, sigfall_class_weight=0):\n",
    "    model = train_model(x_train, y_train, kernel, C, logGamma, degree, coef0, sigfall_class_weight)\n",
    "    decision_values = model.decision_function(x_test)\n",
    "    return optunity.metrics.roc_auc(y_test, decision_values)\n",
    "\n",
    "svm_tuned_auroc = cv_decorator(svm_tuned_auroc)\n",
    "\n",
    "svm_optimal_pars, svm_info, _ = optunity.maximize_structured(svm_tuned_auroc, space, num_evals=150)\n",
    "print(\"Optimal parameters\" + str(svm_optimal_pars))\n",
    "print(\"AUROC of tuned SVM: %1.3f\" % svm_info.optimum)\n",
    "\n",
    "results.append({'model': 'Support Vector Machine',\n",
    "               'Optimal parameters': svm_optimal_pars,\n",
    "               'ROC_AUC': svm_info.optimum\n",
    "               })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "03bc48e1-cab0-46eb-bf1e-81158e423064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal parameters{'solver': 'lsqr', 'sigfall_prior': 0.6107157879477079}\n",
      "AUROC of tuned LDA: 0.672\n"
     ]
    }
   ],
   "source": [
    "# Linear Discriminant Analysis\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "solvers = {'solver': {'svd': { 'sigfall_prior': [0.01,0.99]}, \n",
    "                       'lsqr': { 'sigfall_prior': [0.01,0.99] }, \n",
    "                       'eigen': { 'sigfall_prior': [0.01,0.99] } }}\n",
    "\n",
    "def lda_tuned_auroc(x_train, y_train, x_test, y_test, solver, sigfall_prior=0):\n",
    "    no_fall_prior = 1.0 - sigfall_prior\n",
    "    model = LinearDiscriminantAnalysis(solver=solver, priors=[no_fall_prior,sigfall_prior]).fit(x_train, y_train)    \n",
    "    decision_values = model.predict(x_test)\n",
    "    return optunity.metrics.roc_auc(y_test, decision_values)\n",
    "\n",
    "lda_tuned_auroc = cv_decorator(lda_tuned_auroc)\n",
    "\n",
    "lda_optimal_pars, lda_info, _ = optunity.maximize_structured(lda_tuned_auroc, search_space=solvers, num_evals=100)\n",
    "\n",
    "print(\"Optimal parameters\" + str(lda_optimal_pars))\n",
    "print(\"AUROC of tuned LDA: %1.3f\" % lda_info.optimum)\n",
    "\n",
    "results.append({'model': 'Linear Discriminant Analysis',\n",
    "               'Optimal parameters': lda_optimal_pars,\n",
    "               'ROC_AUC': lda_info.optimum\n",
    "               })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c4668ed3-8e89-4063-917c-b672704f1f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal parameters{'sigfall_prior': 0.8871}\n",
      "AUROC of tuned model: 0.677\n"
     ]
    }
   ],
   "source": [
    "# Quadratic Discriminant Analysis\n",
    "\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "def qda_tuned_auroc(x_train, y_train, x_test, y_test, sigfall_prior):\n",
    "    no_fall_prior = 1.0 - sigfall_prior\n",
    "    model = QuadraticDiscriminantAnalysis(priors=[no_fall_prior,sigfall_prior]).fit(x_train, y_train)\n",
    "    decision_values = model.predict(x_test)\n",
    "    auc = optunity.metrics.roc_auc(y_test, decision_values)\n",
    "    return auc\n",
    "    \n",
    "    \n",
    "qda_tuned_auroc = cv_decorator(qda_tuned_auroc)\n",
    "qda_optimal_pars, qda_info, _ = optunity.maximize(qda_tuned_auroc, solver_name='grid search', num_evals=100, sigfall_prior=[0.01,0.99])\n",
    "\n",
    "print(\"Optimal parameters\" + str(qda_optimal_pars))\n",
    "print(\"AUROC of tuned model: %1.3f\" % qda_info.optimum)\n",
    "\n",
    "results.append({'model': 'Quadratic Discriminant Analysis',\n",
    "               'Optimal parameters': qda_optimal_pars,\n",
    "               'ROC_AUC': qda_info.optimum\n",
    "               })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e531444-0ea2-4f75-854e-e19ca19d420a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest (Decision Tree)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
