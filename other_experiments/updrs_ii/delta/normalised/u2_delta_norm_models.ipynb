{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3228c38a-98d0-4042-9704-39f199e1b10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import optunity\n",
    "import optunity.metrics\n",
    "\n",
    "original_data = np.genfromtxt('../../../working_data/normalised_delta_updrs_sigfall.csv', delimiter=',', skip_header=True)\n",
    "_, n_columns = original_data.shape\n",
    "\n",
    "data = original_data[:,0:(n_columns - 1)]\n",
    "labels = original_data[:,(n_columns - 1)]\n",
    "\n",
    "# Common cross validator for all models\n",
    "cv_decorator = optunity.cross_validated(x=data, y=labels, num_folds=10)\n",
    "\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bdd6087f-d305-48be-af1a-1c38ba3ebbef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal parameters{'sigfall_prior': 0.7695}\n",
      "AUROC of tuned model: 0.683\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "def gnb_tuned_auroc(x_train, y_train, x_test, y_test, sigfall_prior):\n",
    "    no_fall_prior = 1.0 - sigfall_prior\n",
    "    model = GaussianNB(priors=[no_fall_prior,sigfall_prior]).fit(x_train, y_train)\n",
    "    decision_values = model.predict(x_test)\n",
    "    auc = optunity.metrics.roc_auc(y_test, decision_values)\n",
    "    return auc\n",
    "    \n",
    "    \n",
    "gnb_tuned_auroc = cv_decorator(gnb_tuned_auroc)\n",
    "gnb_optimal_pars, gnb_info, _ = optunity.maximize(gnb_tuned_auroc, solver_name='grid search', num_evals=100, sigfall_prior=[0.01,0.99])\n",
    "\n",
    "print(\"Optimal parameters\" + str(gnb_optimal_pars))\n",
    "print(\"AUROC of tuned model: %1.3f\" % gnb_info.optimum)\n",
    "\n",
    "results.append({'model': 'Gaussian Naive Bayes',\n",
    "               'Optimal parameters': gnb_optimal_pars,\n",
    "               'ROC_AUC': gnb_info.optimum\n",
    "               })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "daf7d685-9133-466d-a4f7-669459b7c180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal parameters{'kernel': 'rbf', 'C': 4.973967190410129, 'sigfall_class_weight': 6.765950520833336, 'coef0': None, 'degree': None, 'logGamma': -3.4251259403278747}\n",
      "AUROC of tuned SVM: 0.729\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machines\n",
    "import sklearn.svm\n",
    "\n",
    "# Finding the optimum SVM by abstracting over possible Kernel functions:\n",
    "space = {'kernel': {'linear': {'C': [0, 2], 'sigfall_class_weight':[0,25]},\n",
    "                    'rbf': {'logGamma': [-5, 0], 'C': [0, 10], 'sigfall_class_weight':[0,25]},\n",
    "                    'poly': {'degree': [2, 5], 'C': [0, 5], 'coef0': [0, 2], 'sigfall_class_weight':[0,25]}\n",
    "                    }\n",
    "         }\n",
    "\n",
    "# Need to use conditional func because sci-kit wont take None argument types\n",
    "def train_model(x_train, y_train, kernel, C, logGamma, degree, coef0, sigfall_class_weight):\n",
    "    if kernel == 'linear':\n",
    "        model = sklearn.svm.SVC(kernel=kernel, C=C, class_weight={1: sigfall_class_weight})\n",
    "    elif kernel == 'poly':\n",
    "        model = sklearn.svm.SVC(kernel=kernel, C=C, degree=degree, coef0=coef0, class_weight={1: sigfall_class_weight})\n",
    "    elif kernel == 'rbf':\n",
    "        model = sklearn.svm.SVC(kernel=kernel, C=C, gamma=10 ** logGamma, class_weight={1: sigfall_class_weight})\n",
    "    else:\n",
    "        raise ArgumentError(\"Unknown kernel function: %s\" % kernel)\n",
    "    model.fit(x_train, y_train)\n",
    "    return model\n",
    "\n",
    "def svm_tuned_auroc(x_train, y_train, x_test, y_test, kernel='linear', C=0, logGamma=0, degree=0, coef0=0, sigfall_class_weight=0):\n",
    "    model = train_model(x_train, y_train, kernel, C, logGamma, degree, coef0, sigfall_class_weight)\n",
    "    decision_values = model.decision_function(x_test)\n",
    "    return optunity.metrics.roc_auc(y_test, decision_values)\n",
    "\n",
    "svm_tuned_auroc = cv_decorator(svm_tuned_auroc)\n",
    "\n",
    "svm_optimal_pars, svm_info, _ = optunity.maximize_structured(svm_tuned_auroc, space, num_evals=150)\n",
    "print(\"Optimal parameters\" + str(svm_optimal_pars))\n",
    "print(\"AUROC of tuned SVM: %1.3f\" % svm_info.optimum)\n",
    "\n",
    "results.append({'model': 'Support Vector Machine',\n",
    "               'Optimal parameters': svm_optimal_pars,\n",
    "               'ROC_AUC': svm_info.optimum\n",
    "               })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "03bc48e1-cab0-46eb-bf1e-81158e423064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal parameters{'solver': 'lsqr', 'sigfall_prior': 0.6107157879477079}\n",
      "AUROC of tuned LDA: 0.672\n"
     ]
    }
   ],
   "source": [
    "# Linear Discriminant Analysis\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "solvers = {'solver': {'svd': { 'sigfall_prior': [0.01,0.99]}, \n",
    "                       'lsqr': { 'sigfall_prior': [0.01,0.99] }, \n",
    "                       'eigen': { 'sigfall_prior': [0.01,0.99] } }}\n",
    "\n",
    "def lda_tuned_auroc(x_train, y_train, x_test, y_test, solver, sigfall_prior=0):\n",
    "    no_fall_prior = 1.0 - sigfall_prior\n",
    "    model = LinearDiscriminantAnalysis(solver=solver, priors=[no_fall_prior,sigfall_prior]).fit(x_train, y_train)    \n",
    "    decision_values = model.predict(x_test)\n",
    "    return optunity.metrics.roc_auc(y_test, decision_values)\n",
    "\n",
    "lda_tuned_auroc = cv_decorator(lda_tuned_auroc)\n",
    "\n",
    "lda_optimal_pars, lda_info, _ = optunity.maximize_structured(lda_tuned_auroc, search_space=solvers, num_evals=100)\n",
    "\n",
    "print(\"Optimal parameters\" + str(lda_optimal_pars))\n",
    "print(\"AUROC of tuned LDA: %1.3f\" % lda_info.optimum)\n",
    "\n",
    "results.append({'model': 'Linear Discriminant Analysis',\n",
    "               'Optimal parameters': lda_optimal_pars,\n",
    "               'ROC_AUC': lda_info.optimum\n",
    "               })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c4668ed3-8e89-4063-917c-b672704f1f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal parameters{'sigfall_prior': 0.8871}\n",
      "AUROC of tuned model: 0.677\n"
     ]
    }
   ],
   "source": [
    "# Quadratic Discriminant Analysis\n",
    "\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "def qda_tuned_auroc(x_train, y_train, x_test, y_test, sigfall_prior):\n",
    "    no_fall_prior = 1.0 - sigfall_prior\n",
    "    model = QuadraticDiscriminantAnalysis(priors=[no_fall_prior,sigfall_prior]).fit(x_train, y_train)\n",
    "    decision_values = model.predict(x_test)\n",
    "    auc = optunity.metrics.roc_auc(y_test, decision_values)\n",
    "    return auc\n",
    "    \n",
    "    \n",
    "qda_tuned_auroc = cv_decorator(qda_tuned_auroc)\n",
    "qda_optimal_pars, qda_info, _ = optunity.maximize(qda_tuned_auroc, solver_name='grid search', num_evals=100, sigfall_prior=[0.01,0.99])\n",
    "\n",
    "print(\"Optimal parameters\" + str(qda_optimal_pars))\n",
    "print(\"AUROC of tuned model: %1.3f\" % qda_info.optimum)\n",
    "\n",
    "results.append({'model': 'Quadratic Discriminant Analysis',\n",
    "               'Optimal parameters': qda_optimal_pars,\n",
    "               'ROC_AUC': qda_info.optimum\n",
    "               })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e531444-0ea2-4f75-854e-e19ca19d420a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest (Decision Tree)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c46daa77-0cb4-4d2b-b910-f7a58fc15d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal parameters{'alpha': 0.7283141958125202, 'n_nodes': 44.2946850286549}\n",
      "AUROC of tuned model: 0.500\n"
     ]
    }
   ],
   "source": [
    "# NN using grid search across alpha & nodes (1 hidden layer pressummed satisfactory)\n",
    "# NN 1 - ADAM algorithm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "def nn_adam_tuned_auroc(x_train, y_train, x_test, y_test, alpha, n_nodes):\n",
    "    model = MLPClassifier(solver='adam', alpha=alpha, hidden_layer_sizes=(int(n_nodes)), random_state=123, max_iter=1000).fit(x_train, y_train)\n",
    "    decision_values = model.predict(x_test)\n",
    "    auc = optunity.metrics.roc_auc(y_test, decision_values)\n",
    "    return auc\n",
    "\n",
    "nn_adam_tuned_auroc = cv_decorator(nn_adam_tuned_auroc)\n",
    "nn_adam_optimal_pars, nn_adam_info, _ = optunity.maximize(nn_adam_tuned_auroc, solver_name='random search', num_evals=10, alpha=[0.1,1], n_nodes=[20,120])\n",
    "print(\"Optimal parameters\" + str(nn_adam_optimal_pars))\n",
    "print(\"AUROC of tuned model: %1.3f\" % nn_adam_info.optimum)\n",
    "\n",
    "results.append({'model': 'Neural Net - ADAM',\n",
    "               'Optimal parameters': nn_adam_optimal_pars,\n",
    "               'ROC_AUC': nn_adam_info.optimum\n",
    "               })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "07624e4d-d957-4fdd-a813-0332da9e06f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal parameters{'alpha': 0.4405680121268508, 'n_nodes': 62.47042690345936}\n",
      "AUROC of tuned model: 0.500\n"
     ]
    }
   ],
   "source": [
    "# NN2 - SGD\n",
    "\n",
    "def nn_sgd_tuned_auroc(x_train, y_train, x_test, y_test, alpha, n_nodes):\n",
    "    model = MLPClassifier(solver='sgd', alpha=alpha, hidden_layer_sizes=(int(n_nodes)), random_state=123, max_iter=1000).fit(x_train, y_train)\n",
    "    decision_values = model.predict(x_test)\n",
    "    auc = optunity.metrics.roc_auc(y_test, decision_values)\n",
    "    return auc\n",
    "\n",
    "nn_sgd_tuned_auroc = cv_decorator(nn_sgd_tuned_auroc)\n",
    "nn_sgd_optimal_pars, nn_sgd_info, _ = optunity.maximize(nn_sgd_tuned_auroc, solver_name='random search', num_evals=10, alpha=[0.1,1], n_nodes=[20,120])\n",
    "print(\"Optimal parameters\" + str(nn_sgd_optimal_pars))\n",
    "print(\"AUROC of tuned model: %1.3f\" % nn_sgd_info.optimum)\n",
    "\n",
    "results.append({'model': 'Neural Net - SGD',\n",
    "               'Optimal parameters': nn_sgd_optimal_pars,\n",
    "               'ROC_AUC': nn_sgd_info.optimum\n",
    "               })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "28b643bd-0f98-46fb-b081-76309d5249c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal parameters{'alpha': 4.9314823354150645, 'n_nodes': 24.603104980639955}\n",
      "AUROC of tuned model: 0.500\n"
     ]
    }
   ],
   "source": [
    "# NN3 - lbfgs\n",
    "\n",
    "def nn_lbfgs_tuned_auroc(x_train, y_train, x_test, y_test, alpha, n_nodes):\n",
    "    model = MLPClassifier(solver='lbfgs', alpha=alpha, hidden_layer_sizes=(int(n_nodes)), random_state=123, max_iter=5000).fit(x_train, y_train)\n",
    "    decision_values = model.predict(x_test)\n",
    "    auc = optunity.metrics.roc_auc(y_test, decision_values)\n",
    "    return auc\n",
    "\n",
    "nn_lbfgs_tuned_auroc = cv_decorator(nn_lbfgs_tuned_auroc)\n",
    "nn_lbfgs_optimal_pars, nn_lbfgs_info, _ = optunity.maximize(nn_lbfgs_tuned_auroc, solver_name='random search', num_evals=10, alpha=[0.1,10], n_nodes=[5,60])\n",
    "print(\"Optimal parameters\" + str(nn_lbfgs_optimal_pars))\n",
    "print(\"AUROC of tuned model: %1.3f\" % nn_lbfgs_info.optimum)\n",
    "\n",
    "results.append({'model': 'Neural Net - L-BFGS',\n",
    "               'Optimal parameters': nn_lbfgs_optimal_pars,\n",
    "               'ROC_AUC': nn_lbfgs_info.optimum\n",
    "               })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "126a23fd-158e-4ffc-86c7-46a6544122d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 0, 365, 34)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NN scratch pad - seems they are a little too complex for automated hyper-parameter optimization\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "len(data)\n",
    "xx_train = data[0:1000]\n",
    "xx_test  = data[1001:1400]\n",
    "yy_test  = labels[1001:1400]\n",
    "yy_train = labels[0:1000]\n",
    "\n",
    "# print(xx_train)\n",
    "# print(yy_train)\n",
    "\n",
    "m = MLPClassifier(solver='lbfgs', max_iter=5000, alpha=0.1, hidden_layer_sizes=(15,2)).fit(xx_train, yy_train)\n",
    "dv = m.predict(xx_test)\n",
    "print(optunity.metrics.roc_auc(yy_test, dv))\n",
    "\n",
    "optunity.metrics.contingency_table(yy_test, dv, positive=True)\n",
    "# print(optunity.metrics.roc_auc(yy_test, dv))\n",
    "# print(optunity.metrics.precision(yy_test, dv, positive=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8230ac5f-e179-4664-8092-57d8b96672f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
